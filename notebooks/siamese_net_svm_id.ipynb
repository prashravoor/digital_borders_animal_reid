{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import cv2\n",
    "from torchvision import datasets, transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EmbeddingResnet(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(EmbeddingResnet, self).__init__()\n",
    "\t\t\n",
    "\t\tresnet = resnet50(pretrained=True)\n",
    "\t\tself.features = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool, resnet.layer1, resnet.layer2, resnet.layer3, resnet.layer4, resnet.avgpool)\n",
    "\t\t#self.features = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool, resnet.layer1,  \n",
    "\t\t#\tnn.Dropout(0.5), resnet.layer2, nn.Dropout(0.5), resnet.layer3, nn.Dropout(0.5), resnet.layer4, nn.Dropout(0.5),\n",
    " \t\t#\tresnet.avgpool)\n",
    "\t\tself.act = nn.ReLU6(inplace=True)\n",
    "\t\t# Fix blocks\n",
    "\t\tfor p in self.features[0].parameters(): p.requires_grad=False\n",
    "\t\tfor p in self.features[1].parameters(): p.requires_grad=False\n",
    "\t\tfor p in self.features[6].parameters(): p.requires_grad=True\n",
    "\t\tfor p in self.features[5].parameters(): p.requires_grad=True\n",
    "\t\tfor p in self.features[4].parameters(): p.requires_grad=False\n",
    "\t\tself.act.requires_grad = True\n",
    "\n",
    "\t\tdef set_bn_fix(m):\n",
    "\t\t\tclassname = m.__class__.__name__\n",
    "\t\t\tif classname.find('BatchNorm') != -1:\n",
    "\t\t\t\tfor p in m.parameters(): p.requires_grad=False\n",
    "\n",
    "\t\tself.features.apply(set_bn_fix)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tfeatures = self.features.forward(x)\n",
    "\t\tfeatures = features.view(features.size(0), -1)\n",
    "\t\t#features = F.normalize(features, p=2, dim=1)\n",
    "\t\treturn self.act(features)\n",
    "\n",
    "class EmbeddingDensenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmbeddingDensenet, self).__init__()\n",
    "        self.densenet = torch.hub.load('pytorch/vision:v0.5.0', 'densenet121', pretrained=True)\n",
    "        #self.seq = torch.nn.Sequential(*list(densenet.children())[:-1])\n",
    "        for p in self.densenet.features:\n",
    "            p.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = torch.nn.Sequential(*(list(self.densenet.children())[:-1]))\n",
    "        features = features(x)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        features = F.normalize(features, p=2, dim=1)\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import init\n",
    "import torchvision\n",
    "\n",
    "# Open Reid\n",
    "class ResNet(nn.Module):\n",
    "    __factory = {\n",
    "        18: torchvision.models.resnet18,\n",
    "        34: torchvision.models.resnet34,\n",
    "        50: torchvision.models.resnet50,\n",
    "        101: torchvision.models.resnet101,\n",
    "        152: torchvision.models.resnet152,\n",
    "    }\n",
    "\n",
    "    def __init__(self, depth, pretrained=True, cut_at_pooling=False,\n",
    "                 num_features=0, norm=False, dropout=0, num_classes=0):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.depth = depth\n",
    "        self.pretrained = pretrained\n",
    "        self.cut_at_pooling = cut_at_pooling\n",
    "\n",
    "        # Construct base (pretrained) resnet\n",
    "        if depth not in ResNet.__factory:\n",
    "            raise KeyError(\"Unsupported depth:\", depth)\n",
    "        self.base = ResNet.__factory[depth](pretrained=pretrained)\n",
    "\n",
    "        if not self.cut_at_pooling:\n",
    "            self.num_features = num_features\n",
    "            self.norm = norm\n",
    "            self.dropout = dropout\n",
    "            self.has_embedding = num_features > 0\n",
    "            self.num_classes = num_classes\n",
    "\n",
    "            out_planes = self.base.fc.in_features\n",
    "\n",
    "            # Append new layers\n",
    "            if self.has_embedding:\n",
    "                self.feat = nn.Linear(out_planes, self.num_features)\n",
    "                self.feat_bn = nn.BatchNorm1d(self.num_features)\n",
    "                init.kaiming_normal(self.feat.weight, mode='fan_out')\n",
    "                init.constant(self.feat.bias, 0)\n",
    "                init.constant(self.feat_bn.weight, 1)\n",
    "                init.constant(self.feat_bn.bias, 0)\n",
    "            else:\n",
    "                # Change the num_features to CNN output channels\n",
    "                self.num_features = out_planes\n",
    "            if self.dropout > 0:\n",
    "                self.drop = nn.Dropout(self.dropout)\n",
    "            if self.num_classes > 0:\n",
    "                self.classifier = nn.Linear(self.num_features, self.num_classes)\n",
    "                init.normal(self.classifier.weight, std=0.001)\n",
    "                init.constant(self.classifier.bias, 0)\n",
    "\n",
    "        if not self.pretrained:\n",
    "            self.reset_params()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for name, module in self.base._modules.items():\n",
    "            if name == 'avgpool':\n",
    "                break\n",
    "            x = module(x)\n",
    "\n",
    "        if self.cut_at_pooling:\n",
    "            return x\n",
    "\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        if self.has_embedding:\n",
    "            x = self.feat(x)\n",
    "            x = self.feat_bn(x)\n",
    "        if self.norm:\n",
    "            x = F.normalize(x)\n",
    "        elif self.has_embedding:\n",
    "            x = F.relu(x)\n",
    "        if self.dropout > 0:\n",
    "            x = self.drop(x)\n",
    "        if self.num_classes > 0:\n",
    "            x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def reset_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    init.constant(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant(m.weight, 1)\n",
    "                init.constant(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal(m.weight, std=0.001)\n",
    "                if m.bias is not None:\n",
    "                    init.constant(m.bias, 0)\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    return ResNet(50, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, embeddingNet):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.embeddingNet = embeddingNet\n",
    "\n",
    "    def forward(self, i1, i2, i3):\n",
    "        E1 = self.embeddingNet(i1)\n",
    "        E2 = self.embeddingNet(i2)\n",
    "        E3 = self.embeddingNet(i3)\n",
    "        # dist_a = F.pairwise_distance(E1, E2, 2)\n",
    "        # dist_b = F.pairwise_distance(E1, E3, 2)\n",
    "        return E1, E2, E3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletNetInference(TripletNet):\n",
    "    def __init__(self, embeddingNet):\n",
    "        super(TripletNetInference, self).__init__(embeddingNet)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.embeddingNet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Reid\n",
    "ckp = torch.load('../open-reid/examples/logs/model_best.pth.tar')\n",
    "model = resnet50(num_features=1024,num_classes=4096)\n",
    "model.load_state_dict(ckp['state_dict'])\n",
    "#model.cut_at_pooling = True\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to('cuda')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding: utf-8\n",
    "\"\"\"\n",
    "@author:  liaoxingyu\n",
    "@contact: sherlockliao01@gmail.com\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, last_stride=2, block=Bottleneck, layers=[3, 4, 6, 3]):\n",
    "        self.inplanes = 64\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        # self.relu = nn.ReLU(inplace=True)   # add missed relu\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        #self.dropout = nn.Dropout(0.5)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.layer4 = self._make_layer(\n",
    "            block, 512, layers[3], stride=last_stride)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        # x = self.relu(x)    # add missed relu\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        #x = self.dropout(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def load_param(self, model_path):\n",
    "        param_dict = torch.load(model_path)\n",
    "        for i in param_dict:\n",
    "            if 'fc' in i:\n",
    "                continue\n",
    "            self.state_dict()[i].copy_(param_dict[i])\n",
    "\n",
    "    def random_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "\n",
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight, a=0, mode='fan_out')\n",
    "        nn.init.constant_(m.bias, 0.0)\n",
    "    elif classname.find('Conv') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        if m.affine:\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_classifier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight, std=0.001)\n",
    "        if m.bias:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "\n",
    "class Baseline(nn.Module):\n",
    "    in_planes = 2048\n",
    "\n",
    "    def __init__(self, num_classes, last_stride, model_path, neck, neck_feat, model_name, pretrain_choice):\n",
    "        super(Baseline, self).__init__()\n",
    "        if model_name == 'resnet18':\n",
    "            self.in_planes = 512\n",
    "            self.base = ResNet(last_stride=last_stride, \n",
    "                               block=BasicBlock, \n",
    "                               layers=[2, 2, 2, 2])\n",
    "        elif model_name == 'resnet34':\n",
    "            self.in_planes = 512\n",
    "            self.base = ResNet(last_stride=last_stride,\n",
    "                               block=BasicBlock,\n",
    "                               layers=[3, 4, 6, 3])\n",
    "        elif model_name == 'resnet50':\n",
    "            self.base = ResNet(last_stride=last_stride,\n",
    "                               block=Bottleneck,\n",
    "                               layers=[3, 4, 6, 3])\n",
    "        elif model_name == 'resnet101':\n",
    "            self.base = ResNet(last_stride=last_stride,\n",
    "                               block=Bottleneck, \n",
    "                               layers=[3, 4, 23, 3])\n",
    "        elif model_name == 'resnet152':\n",
    "            self.base = ResNet(last_stride=last_stride, \n",
    "                               block=Bottleneck,\n",
    "                               layers=[3, 8, 36, 3])\n",
    "            \n",
    "        elif model_name == 'se_resnet50':\n",
    "            self.base = SENet(block=SEResNetBottleneck, \n",
    "                              layers=[3, 4, 6, 3], \n",
    "                              groups=1, \n",
    "                              reduction=16,\n",
    "                              dropout_p=None, \n",
    "                              inplanes=64, \n",
    "                              input_3x3=False,\n",
    "                              downsample_kernel_size=1, \n",
    "                              downsample_padding=0,\n",
    "                              last_stride=last_stride) \n",
    "        elif model_name == 'se_resnet101':\n",
    "            self.base = SENet(block=SEResNetBottleneck, \n",
    "                              layers=[3, 4, 23, 3], \n",
    "                              groups=1, \n",
    "                              reduction=16,\n",
    "                              dropout_p=None, \n",
    "                              inplanes=64, \n",
    "                              input_3x3=False,\n",
    "                              downsample_kernel_size=1, \n",
    "                              downsample_padding=0,\n",
    "                              last_stride=last_stride)\n",
    "        elif model_name == 'se_resnet152':\n",
    "            self.base = SENet(block=SEResNetBottleneck, \n",
    "                              layers=[3, 8, 36, 3],\n",
    "                              groups=1, \n",
    "                              reduction=16,\n",
    "                              dropout_p=None, \n",
    "                              inplanes=64, \n",
    "                              input_3x3=False,\n",
    "                              downsample_kernel_size=1, \n",
    "                              downsample_padding=0,\n",
    "                              last_stride=last_stride)  \n",
    "        elif model_name == 'se_resnext50':\n",
    "            self.base = SENet(block=SEResNeXtBottleneck,\n",
    "                              layers=[3, 4, 6, 3], \n",
    "                              groups=32, \n",
    "                              reduction=16,\n",
    "                              dropout_p=None, \n",
    "                              inplanes=64, \n",
    "                              input_3x3=False,\n",
    "                              downsample_kernel_size=1, \n",
    "                              downsample_padding=0,\n",
    "                              last_stride=last_stride) \n",
    "        elif model_name == 'se_resnext101':\n",
    "            self.base = SENet(block=SEResNeXtBottleneck,\n",
    "                              layers=[3, 4, 23, 3], \n",
    "                              groups=32, \n",
    "                              reduction=16,\n",
    "                              dropout_p=None, \n",
    "                              inplanes=64, \n",
    "                              input_3x3=False,\n",
    "                              downsample_kernel_size=1, \n",
    "                              downsample_padding=0,\n",
    "                              last_stride=last_stride)\n",
    "        elif model_name == 'senet154':\n",
    "            self.base = SENet(block=SEBottleneck, \n",
    "                              layers=[3, 8, 36, 3],\n",
    "                              groups=64, \n",
    "                              reduction=16,\n",
    "                              dropout_p=0.2, \n",
    "                              last_stride=last_stride)\n",
    "        elif model_name == 'resnet50_ibn_a':\n",
    "            self.base = resnet50_ibn_a(last_stride)\n",
    "        elif model_name == 'densenet':\n",
    "            self.base = models.densenet121(pretrained=True)\n",
    "            self.base.classifier = nn.Linear(1024, self.in_planes)\n",
    "            \n",
    "        if pretrain_choice == 'imagenet':\n",
    "            self.base.load_param(model_path)\n",
    "            print('Loading pretrained ImageNet model......')\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        # self.gap = nn.AdaptiveMaxPool2d(1)\n",
    "        self.num_classes = num_classes\n",
    "        self.neck = neck\n",
    "        self.neck_feat = neck_feat\n",
    "\n",
    "        if self.neck == 'no':\n",
    "            self.classifier = nn.Linear(self.in_planes, self.num_classes)\n",
    "            # self.classifier = nn.Linear(self.in_planes, self.num_classes, bias=False)     # new add by luo\n",
    "            # self.classifier.apply(weights_init_classifier)  # new add by luo\n",
    "        elif self.neck == 'bnneck':\n",
    "            self.bottleneck = nn.BatchNorm1d(self.in_planes)\n",
    "            self.bottleneck.bias.requires_grad_(False)  # no shift\n",
    "            self.classifier = nn.Linear(self.in_planes, self.num_classes, bias=False)\n",
    "\n",
    "            self.bottleneck.apply(weights_init_kaiming)\n",
    "            self.classifier.apply(weights_init_classifier)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        global_feat = self.gap(self.base(x))  # (b, 2048, 1, 1)\n",
    "        #global_feat = self.base(x)\n",
    "        global_feat = global_feat.view(global_feat.shape[0], -1)  # flatten to (bs, 2048)\n",
    "        if not self.training:\n",
    "            return global_feat\n",
    "\n",
    "        if self.neck == 'no':\n",
    "            feat = global_feat\n",
    "        elif self.neck == 'bnneck':\n",
    "            feat = self.bottleneck(global_feat)  # normalize for angular softmax\n",
    "\n",
    "        if self.training:\n",
    "            cls_score = self.classifier(feat)\n",
    "            return cls_score, global_feat  # global feature for triplet loss\n",
    "        else:\n",
    "            if self.neck_feat == 'after':\n",
    "                # print(\"Test with feature after BN\")\n",
    "                return feat\n",
    "            else:\n",
    "                # print(\"Test with feature before BN\")\n",
    "                return global_feat\n",
    "\n",
    "    def load_param(self, trained_path):\n",
    "        param_dict = torch.load(trained_path)\n",
    "        for k, v in param_dict.state_dict().items():\n",
    "            if 'classifier' in k:\n",
    "                continue\n",
    "            self.state_dict()[k].copy_(param_dict.state_dict()[k])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to('cuda')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckp = torch.load('../pytorch-siamese-triplet/data/resnet_triplet_big/checkpoint_30.pth')\n",
    "embeddingNet = EmbeddingResnet()\n",
    "resnet = TripletNetInference(embeddingNet)\n",
    "model = nn.DataParallel(resnet)\n",
    "model = model.to('cuda')\n",
    "model.load_state_dict(ckp['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ckp = torch.load('amur/model/checkpoint_5.pth')\n",
    "model_dict = ckp['state_dict']\n",
    "embeddingNet = EmbeddingResnet()\n",
    "#embeddingNet = EmbeddingDensenet()\n",
    "model_dict_mod = {}\n",
    "for key, value in model_dict.items():\n",
    "    new_key = '.'.join(key.split('.')[2:])\n",
    "    #print(new_key)\n",
    "    model_dict_mod[new_key] = value\n",
    "model = embeddingNet.to('cuda')\n",
    "#model.load_state_dict(model_dict_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection import ObjectDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "detector = ObjectDetector('ssd/saved_model')\n",
    "detector.loadModel()\n",
    "detector.getBoundingBoxes(cv2.imread('amur_detection_small\\\\0042.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Read in all ELP images\n",
    "img_folder = 'amur/plain_reid_tf/'\n",
    "train_classes = [x for x in os.listdir(os.path.join(img_folder, 'train'))]\n",
    "val_classes = [x for x in os.listdir(os.path.join(img_folder, 'valid'))]\n",
    "\n",
    "x_train_names = []\n",
    "y_train = []\n",
    "x_val_names = []\n",
    "y_val = []\n",
    "\n",
    "for cls in train_classes:\n",
    "    base_path = os.path.join(img_folder, os.path.join('train', cls))\n",
    "    imgs = [x for x in os.listdir(base_path) if x.endswith('.jpg')]\n",
    "    if len(imgs) < 3:\n",
    "        print('Skipping class {}'.format(cls))\n",
    "        continue\n",
    "    for img in imgs:\n",
    "        x_train_names.append(os.path.join(base_path, img))\n",
    "        y_train.append(cls)\n",
    "\n",
    "for cls in val_classes:\n",
    "    base_path = os.path.join(img_folder, os.path.join('valid', cls))\n",
    "    imgs = [x for x in os.listdir(base_path) if x.endswith('.jpg')]\n",
    "    for img in imgs:\n",
    "        x_val_names.append(os.path.join(base_path, img))\n",
    "        y_val.append(cls)\n",
    "\n",
    "print('Train classes: {}, Valid Classes: {}'.format(len(set(y_train)), len(set(y_val))))\n",
    "print('Total Train images: {}, Total validation images: {}'.format(len(x_train_names), len(x_val_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../reid-strong-baseline')\n",
    "\n",
    "#modelpath = 'trained_models/elp_no_ls_12_ins_resnet50_model_80.pth'\n",
    "modelpath = 'trained_models/amur_no_ls_8_ins_99_acc_resnet50_model_100.pth'\n",
    "# Strong Reid\n",
    "#ckp = torch.load('../reid-strong-baseline/amur_test1/resnet50_checkpoint_850.pth')\n",
    "#model = Baseline(107,1,'C:\\\\Users\\\\Prashanth\\\\.cache\\\\torch\\\\checkpoints\\\\resnet50-19c8e357.pth', 'bnneck', 'after', 'resnet50', 'self')\n",
    "#model = torch.load('../reid-strong-baseline/amur_test1/resnet50_model_120.pth')\n",
    "#model = torch.load('../reid-strong-baseline/jag_test/resnet50_model_120.pth')\n",
    "#model = torch.load('../reid-strong-baseline/elp_test/resnet50_model_60.pth')\n",
    "#model = torch.load('trained_models/jag_no_ls_8_ins_resnet50_model_80.pth')\n",
    "#model = torh.load('trained_models/amur_99.9_strong_reid_good_resnet50_model_50.pth')\n",
    "model = torch.load(modelpath, torch.device('cpu'))\n",
    "#model.cut_at_pooling = True\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to('cpu')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Read in all ELP images\n",
    "#img_folder = 'ELPephants/reid_faces_renamed/test'\n",
    "#img_folder = 'ELPephants/reid_faces_renamed/test/'\n",
    "#img_folder = 'jaguars/reid_strong_baseline/train'\n",
    "img_folder = 'amur/plain_reid_train/train/'\n",
    "images = [x for x in os.listdir(img_folder) if x.endswith('.jpg')]\n",
    "\n",
    "with open(os.path.join(img_folder, 'class_mapping.txt')) as f:\n",
    "    mapping = {x.split('\\t')[0].strip() : x.split('\\t')[1].strip() for x in f.readlines()}\n",
    "\n",
    "mapping = {os.path.join(img_folder, k):v for k,v in mapping.items() if k in images}\n",
    "\n",
    "rev_map = dict()\n",
    "for k,v in mapping.items():\n",
    "    if v not in rev_map:\n",
    "        rev_map[v] = []\n",
    "    rev_map[v].append(k)\n",
    "\n",
    "rev_map = {k:v for k,v in rev_map.items() if len(v) > 1}\n",
    "\n",
    "x_train_names = []\n",
    "y_train = []\n",
    "x_val_names = []\n",
    "y_val = []\n",
    "\n",
    "for k,v in rev_map.items():\n",
    "    # 30% split of each class to training and test\n",
    "    num_el = int(np.ceil(len(v) * 0.3))\n",
    "    val = np.random.choice(v, num_el, replace=False)\n",
    "    train = [x for x in v if x not in val]\n",
    "    x_train_names.extend(train)\n",
    "    x_val_names.extend(val)\n",
    "    y_train.extend([k for _ in range(len(train))])\n",
    "    y_val.extend([k for _ in range(len(val))])\n",
    "    assert len(x_train_names) == len(y_train)\n",
    "    assert len(x_val_names) == len(y_val)\n",
    "\n",
    "def shuffle(x,y):\n",
    "    c = list(zip(x,y))\n",
    "    np.random.shuffle(c)\n",
    "    return zip(*c)\n",
    "\n",
    "# Verify correctness of data\n",
    "for index in range(len(x_val_names)):\n",
    "    assert mapping[x_val_names[index]] == y_val[index], '{} != {}'.format(mapping[x_val_names[index]],y_val[index])\n",
    "    \n",
    "for index in range(len(x_train_names)):\n",
    "    assert mapping[x_train_names[index]] == y_train[index]\n",
    "    \n",
    "# Map to congiguous identities\n",
    "num_ids = len(set(y_train))\n",
    "num_t_ids = len(set(y_val))\n",
    "\n",
    "assert num_ids == num_t_ids\n",
    "\n",
    "id_map = dict()\n",
    "counter = 0\n",
    "for id in y_train:\n",
    "    if not id in id_map:\n",
    "        id_map[id] = counter\n",
    "        counter += 1\n",
    "\n",
    "rev_id_map = {v:k for k,v in id_map.items()}\n",
    "        \n",
    "y_train_old, y_val_old = y_train, y_val\n",
    "y_train = np.array([id_map[x] for x in y_train])\n",
    "y_val = np.array([id_map[x] for x in y_val])\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    assert y_train_old[i] == rev_id_map[y_train[i]]\n",
    "\n",
    "for i in range(len(y_val)):\n",
    "    assert y_val_old[i] == rev_id_map[y_val[i]]\n",
    "\n",
    "x_train_names, y_train = shuffle(x_train_names, y_train)\n",
    "x_val_names, y_val = shuffle(x_val_names, y_val)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "print('Train classes: {}, Valid Classes: {}'.format(len(set(y_train)), len(set(y_val))))\n",
    "print('Total Train images: {}, Total validation images: {}'.format(len(x_train_names), len(x_val_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(img):\n",
    "    img = cv2.resize(img, (256,256))\n",
    "    img = img[:,:,(2,1,0)]\n",
    "    transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                           ])\n",
    "    img = transform(img)\n",
    "    img = img.reshape((1, 3, 256,256))\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        img = torch.autograd.Variable(img).cuda()\n",
    "        res = model(img)\n",
    "        #res = torch.sigmoid(res)\n",
    "        return res.cpu().detach().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../reid-strong-baseline')\n",
    "\n",
    "mdl = Baseline(len(set(y_train)), 1, modelpath, 'bnneck', 'after', 'resnet50', 'self')\n",
    "mdl.load_param(modelpath)\n",
    "\n",
    "\n",
    "model = mdl\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to('cuda')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature for each image in training set\n",
    "start = time.time()\n",
    "x_train = np.asarray([extract_feature(cv2.imread(x)) for x in x_train_names])\n",
    "x_val = np.asarray([extract_feature(cv2.imread(x)) for x in x_val_names])\n",
    "total_time = time.time() - start\n",
    "print('Total FE time: {:.4f}s, Average time per image: {:.4f}s'.format(\n",
    "    total_time, total_time/(len(x_train) + len(x_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "def createSvmModel(kernelType='linear'):\n",
    "    if 'poly' == kernelType:\n",
    "        return svm.SVC(kernel=kernelType, gamma='scale', degree=2)\n",
    "    return svm.SVC(kernel=kernelType, gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmModel = createSvmModel()\n",
    "svmModel = svmModel.fit(x_train, y_train)\n",
    "#svmModel = svmModel.fit(x_val, y_val)\n",
    "#svmModel = svmModel.fit(x_train_new, y_train_new)\n",
    "\n",
    "y_pred = svmModel.predict(x_train)\n",
    "acc = metrics.accuracy_score(y_train, y_pred)\n",
    "print('Training Accuracy: {:.4f}'.format(acc))\n",
    "\n",
    "y_pred = svmModel.predict(x_val)\n",
    "acc = metrics.accuracy_score(y_val, y_pred)\n",
    "print('Validation Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = cv2.imread('videos/tiger_1.jpg')\n",
    "im2 = cv2.imread('videos/tiger_2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = ('videos/tiger_1.jpg')\n",
    "im2 = ('videos/tiger_2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sigmoid(torch.tensor(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb_from_image(imname, detector):\n",
    "    img = cv2.imread(imname)\n",
    "    bounding_boxes = detector.getBoundingBoxes(img)\n",
    "    if len(bounding_boxes) == 1:\n",
    "        box = bounding_boxes[0].bounding_box\n",
    "        img = img[box.ymin:box.ymax, box.xmin:box.xmax,:]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature for each image in training set\n",
    "x_train = np.asarray([extract_feature(get_bb_from_image(x, detector)) for x in x_train_names])\n",
    "x_val = np.asarray([extract_feature(get_bb_from_image(x, detector)) for x in x_val_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict()\n",
    "for k,v in zip(x_val_names, y_val):\n",
    "    if not v in mapping:\n",
    "        mapping[v] = []\n",
    "    mapping[v].append(k)\n",
    "#mapping = {k:v for k,v in mapping.items() if len(v) > 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#im1 = mapping[9][2]\n",
    "#im2 = mapping[8][0]\n",
    "im1 = 'images/reid/cub_2.png'\n",
    "im2 = 'images/reid/cub_4.png'\n",
    "img1 = cv2.imread(im1)\n",
    "img2 = cv2.imread(im2)\n",
    "\n",
    "#img1 = get_bb_from_image(im1, detector)\n",
    "#img2 = get_bb_from_image(im2, detector)\n",
    "f1 = extract_feature(img1)\n",
    "f2 = extract_feature(img2)\n",
    "\n",
    "fig,ax = plt.subplots(1,2)\n",
    "ax[0].imshow(img1)\n",
    "ax[1].imshow(img2)\n",
    "print(np.linalg.norm(f1 - f2))\n",
    "print('Cos Sim: {:.4f}'.format(1 - spatial.distance.cosine(f1, f2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distmap = dict()\n",
    "for i in range(len(y_val)):\n",
    "    if not y_val[i] in distmap:\n",
    "        distmap[y_val[i]] = []\n",
    "        \n",
    "    distmap[y_val[i]].append(x_val[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "distmat = distance_matrix(x_train_t, x_train_t)\n",
    "indices = np.argsort(distmat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = (y_train[indices] == (y_train)[:, np.newaxis]).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train)):\n",
    "    cmc = matches[i]\n",
    "    print(cmc.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices[0] == np.array(sorted(y_train[:,np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[indices[1]][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#cosine = cosine_similarity(x_train, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainlist = x_train.tolist()\n",
    "xvallist = x_val.tolist()\n",
    "ytrainlist = list(y_train)\n",
    "yvallist = list(y_val)\n",
    "for im in os.listdir('images/reid'):\n",
    "    xtrainlist.append(extract_feature(cv2.imread(os.path.join('images/reid', im))))\n",
    "    if 'cub' in im:\n",
    "        ytrainlist.append(1000)\n",
    "    else:\n",
    "        ytrainlist.append(1001)\n",
    "\n",
    "xvallist.append(xtrainlist[-1])\n",
    "yvallist.append(yvallist[-1])\n",
    "xtrainlist = xtrainlist[:-1]\n",
    "ytrainlist = ytrainlist[:-1]\n",
    "\n",
    "x_train_new = np.array(xtrainlist)\n",
    "y_train_new = np.array(ytrainlist)\n",
    "x_val_new = np.array(xvallist)\n",
    "y_val_new = np.array(yvallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.asarray([extract_feature(cv2.imread(x)) for x in x_val_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1 = []\n",
    "x_val1 = []\n",
    "for i in range(len(x_train)):\n",
    "    x_train[i][x_train[i] == 0] = 0.000001\n",
    "\n",
    "for i in range(len(x_val)):\n",
    "    x_val[i][x_val[i] == 0] = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1 = np.log(x_train1)\n",
    "x_val1 = np.log(x_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = []\n",
    "for k,v in mapping.items():\n",
    "    distr.append((k,len(v)))\n",
    "\n",
    "print(sorted(distr, key=lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(imname, model):\n",
    "    img = cv2.imread(imname)\n",
    "    feat = np.array([extract_feature(img)])\n",
    "    res = model.predict(feat)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(im2, svmModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svmModel.predict(x_train_new)\n",
    "acc = metrics.accuracy_score(y_train_new, y_pred)\n",
    "print('Training Accuracy: {:.4f}'.format(acc))\n",
    "\n",
    "y_pred = svmModel.predict(x_val_new)\n",
    "acc = metrics.accuracy_score(y_val_new, y_pred)\n",
    "print('Validation Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict('jaguars/reid_for_tensorflow/31/j128_28_0.jpg', svmModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict('elp_small/373_Ariel II right side_26Jan2016.jpg', svmModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'amur/plain_reid_train/train/000037.jpg'\n",
    "if image in mapping:\n",
    "    print('Original: {}'.format(mapping[image]))\n",
    "image = 'images/reid/cub_5.png'\n",
    "num = predict(image, svmModel)\n",
    "print(num)\n",
    "#plt.imshow(cv2.imread(image))\n",
    "#showAllTigers(rev_map, num, img_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'jaguars/reid_strong_baseline/test/j128_0_0.jpg'\n",
    "if image in mapping:\n",
    "    print('Original: {}'.format(mapping[image]))\n",
    "#image = 'images/reid/tiger_3.png'\n",
    "num = predict(image, svmModel)\n",
    "print(num)\n",
    "#plt.imshow(cv2.imread(image))\n",
    "#showAllTigers(rev_map, num, img_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAllTigers(rev_map, num, folder):\n",
    "    files = np.array(rev_map[str(num)])\n",
    "    size = 2 * (files.size//2)\n",
    "    files = files[:size]\n",
    "    files = files.reshape(2, files.size//2)\n",
    "    fig, axes = plt.subplots(files.shape[0], files.shape[1], figsize=(24,3))\n",
    "    m,n = files.shape\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            image = cv2.imread(files[i][j])\n",
    "            if image is None:\n",
    "                print('None!')\n",
    "                continue\n",
    "            axes[i][j].imshow(image)\n",
    "            axes[i][j].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showAllTigers(rev_map, 1, img_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTsne(x_train, y_train, title):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    X_embedded = TSNE(n_components=2).fit_transform(x_train)\n",
    "    x, y = X_embedded[:,0], X_embedded[:,1]\n",
    "    colors = plt.cm.rainbow(np.linspace(0,1,10))\n",
    "    sc = ax.scatter(x, y, c=[int(x) for x in y_train], cmap=matplotlib.colors.ListedColormap(colors))\n",
    "    plt.colorbar(sc)\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newx = np.concatenate((x_train, x_val), axis=0)\n",
    "newy = np.concatenate((y_train, y_val), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#createTsne(newx, newy, 'Elephants - Feature Vector projections over Test set')\n",
    "#createTsne(x_train, y_train, 'Tiger - Feature Vector projections over Train set')\n",
    "createTsne(x_val, y_val, 'Tiger - Feature Vector projections over Validation set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "X_embedded = TSNE(n_components=2).fit_transform(x_train)\n",
    "x, y = X_embedded[:,0], X_embedded[:,1]\n",
    "colors = plt.cm.rainbow(np.linspace(0,1,10))\n",
    "sc = ax.scatter(x, y, c=[int(x) for x in y_train], cmap=matplotlib.colors.ListedColormap(colors))\n",
    "plt.colorbar(sc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "X_embedded = TSNE(n_components=2).fit_transform(x_val)\n",
    "x, y = X_embedded[:,0], X_embedded[:,1]\n",
    "colors = plt.cm.rainbow(np.linspace(0,1,10))\n",
    "sc = ax.scatter(x, y, c=[int(x) for x in y_val], cmap=matplotlib.colors.ListedColormap(colors))\n",
    "plt.colorbar(sc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "X_embedded = TSNE(n_components=2).fit_transform(x_train1)\n",
    "x, y = X_embedded[:,0], X_embedded[:,1]\n",
    "colors = plt.cm.rainbow(np.linspace(0,1,10))\n",
    "sc = ax.scatter(x, y, c=[int(x) for x in y_train], cmap=matplotlib.colors.ListedColormap(colors))\n",
    "plt.colorbar(sc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=58, random_state=0).fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [str(x) for x in kmeans.predict(x_val)]\n",
    "acc = metrics.accuracy_score(y_val, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.densenet201(pretrained=True)\n",
    "model.classifier = nn.Linear(in_features=1920, out_features=2048)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in mdl.features:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImagesByIndex(indices, nameslist, targetlist, qidx, valnames, valtgt):\n",
    "    files = np.array(nameslist)[indices]\n",
    "    crct = (np.array(targetlist)[indices] == valtgt[qidx])\n",
    "    size = 2 * (files.size//2)\n",
    "    files = files[:size]\n",
    "    files = files.reshape(2, files.size//2)\n",
    "    tgtlist = np.array(targetlist)[indices].reshape(2, files.size//2)\n",
    "    crct = crct.reshape(2, files.size//2)\n",
    "    m,n = files.shape\n",
    "    w,h = 300,300\n",
    "    thickness = 6\n",
    "    #fig, axes = plt.subplots(m+1, n, figsize=(6,6))\n",
    "    fig, axes = plt.subplots(m+1, n)\n",
    "\n",
    "    ax = axes[0][0]\n",
    "    ax.imshow(cv2.imread(valnames[qidx][:,:,(2,1,0)]))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(valtgt[qidx])\n",
    "    fig.tight_layout()\n",
    "    for i in range(n):\n",
    "        axes[0][i].axis('off')\n",
    "\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            image = cv2.imread(files[i][j])\n",
    "            image = cv2.resize(image, (w,h))\n",
    "            if crct[i][j]:\n",
    "                image = cv2.rectangle(image, (thickness,thickness), (w-thickness,h-thickness), color=(0,255,0), thickness=thickness)\n",
    "            else:\n",
    "                image = cv2.rectangle(image, (thickness,thickness), (w-thickness,h-thickness), color=(0,0,255), thickness=thickness)\n",
    "            if image is None:\n",
    "                print('None!')\n",
    "                continue\n",
    "            axes[i+1][j].imshow(image[:,:,(2,1,0)])\n",
    "            axes[i+1][j].axis('off')\n",
    "            axes[i+1][j].set_title(tgtlist[i][j])\n",
    "    fig.tight_layout(pad=0, w_pad=0, h_pad=0)\n",
    "    #fig,ax = fig.subplots(1, 1, figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showSixImagesByIndex(indices, nameslist, targetlist, qidx, valnames, valtgt, rank=5):\n",
    "    m = len(qidx)\n",
    "    n = rank + 1 # first image is query\n",
    "    #fig, axes = plt.subplots(m, n, figsize=(30,15))\n",
    "    fig, axes = plt.subplots(m, n, figsize=(12,12))\n",
    "    w,h = 300,300\n",
    "    thickness = 6\n",
    "        \n",
    "    for i in range(m):\n",
    "        ax = axes[i][0]\n",
    "        img = cv2.imread(valnames[qidx[i]])[:,:,(2,1,0)]\n",
    "        img = cv2.resize(img, (w,h))\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(valtgt[qidx[i]])\n",
    "        \n",
    "        files = np.array(nameslist)[indices[i]]\n",
    "        crct = (np.array(targetlist)[indices[i]] == valtgt[qidx[i]])\n",
    "        tgtlist = np.array(targetlist)[indices[i]]\n",
    "        for j in range(1,n):\n",
    "            image = cv2.imread(files[j-1])\n",
    "            image = cv2.resize(image, (w,h))\n",
    "            if crct[j-1]:\n",
    "                image = cv2.rectangle(image, (thickness,thickness), (w-thickness,h-thickness), color=(0,255,0), thickness=thickness)\n",
    "            else:\n",
    "                image = cv2.rectangle(image, (thickness,thickness), (w-thickness,h-thickness), color=(0,0,255), thickness=thickness)\n",
    "            if image is None:\n",
    "                print('None!')\n",
    "                continue\n",
    "            axes[i][j].imshow(image[:,:,(2,1,0)])\n",
    "            axes[i][j].axis('off')\n",
    "            axes[i][j].set_title(tgtlist[j-1])\n",
    "    #fig.subplots_adjust(hspace=0)\n",
    "    #fig.tight_layout(pad=-0.9)\n",
    "    fig.subplots_adjust(wspace=.1, hspace=0)\n",
    "    #fig,ax = fig.subplots(1, 1, figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating accuracy of identification - Qualitative\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "distmat = distance_matrix(x_val, x_train)\n",
    "m, n = distmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 5\n",
    "numimages = 5\n",
    "resindices = []\n",
    "resqidx = []\n",
    "ids = np.random.choice(list(range(0,len(set(y_val)))), numimages, replace=False)\n",
    "id_map = dict()\n",
    "for i in range(len(y_val)):\n",
    "    if y_val[i] not in ids:\n",
    "        continue\n",
    "\n",
    "    x = y_val[i]\n",
    "    if not x in id_map:\n",
    "        id_map[x] = []\n",
    "    id_map[x].append(i)\n",
    "\n",
    "#for x in range(numimages):\n",
    "for x in ids:\n",
    "    i = np.random.choice(id_map[x], replace=False)\n",
    "    #i = ids[x]\n",
    "    resqidx.append(i)\n",
    "    distances = distmat[i]\n",
    "    indices = np.argsort(distances)[:rank]\n",
    "    resindices.append(indices)\n",
    "    org_classes = y_train[indices]\n",
    "    org_class = y_val[i]\n",
    "    matches = (org_class == org_classes).astype(int)\n",
    "    cmc = matches.cumsum()\n",
    "    cmc[cmc > 1] = 1\n",
    "    print('Top-{} Rank: {:.4f}'.format(rank, cmc.sum()/len(cmc)))\n",
    "    print('Total correct identities: {}/{}'.format(matches.sum(), rank))\n",
    "\n",
    "showSixImagesByIndex(resindices, x_train_names, y_train, resqidx, x_val_names, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = distmat[0]\n",
    "indices = np.argsort(d)[:10]\n",
    "org_classes = y_train[indices]\n",
    "org_class = y_val[0]\n",
    "mat = (org_class == org_classes).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = mat.cumsum()\n",
    "mat[mat > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mat == 1).sum() / len(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showImagesByIndex(org_classes, x_train_names, y_train, 0, x_val_names, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
